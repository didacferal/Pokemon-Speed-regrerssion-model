{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XteWaKK4TLOw",
        "outputId": "6de98028-47fc-4ff5-9778-e7ffd1788f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.26.14)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYu4WNbFTcoI",
        "outputId": "94580215-2f66-4c5d-edf8-7b81be00148f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "IOgpPyZdUxTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "wHJxCVnbVHUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmMRK0wcVZgR",
        "outputId": "252dcd05-5396-4c8a-aa96-8625193dff65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: missing operand after ‘600~/.kaggle/kaggle.json’\n",
            "Try 'chmod --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTYCE0tTVgho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the dataset\n"
      ],
      "metadata": {
        "id": "cZiQEF0eR1Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d abcsds/pokemon\n",
        "!unzip pokemon.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbXqoJHKRykY",
        "outputId": "ee9ef37a-5b92-4b97-f9ad-85d9c3b5af8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pokemon.zip to /content\n",
            "\r  0% 0.00/14.9k [00:00<?, ?B/s]\n",
            "\r100% 14.9k/14.9k [00:00<00:00, 10.3MB/s]\n",
            "Archive:  pokemon.zip\n",
            "  inflating: Pokemon.csv             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "original_df = pd.read_csv('Pokemon.csv')\n",
        "original_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "__N6ivlaVw2Y",
        "outputId": "e297888b-f420-4fdf-cfb6-6b651051d11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       #                   Name   Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
              "0      1              Bulbasaur    Grass  Poison    318  45      49       49   \n",
              "1      2                Ivysaur    Grass  Poison    405  60      62       63   \n",
              "2      3               Venusaur    Grass  Poison    525  80      82       83   \n",
              "3      3  VenusaurMega Venusaur    Grass  Poison    625  80     100      123   \n",
              "4      4             Charmander     Fire     NaN    309  39      52       43   \n",
              "..   ...                    ...      ...     ...    ...  ..     ...      ...   \n",
              "795  719                Diancie     Rock   Fairy    600  50     100      150   \n",
              "796  719    DiancieMega Diancie     Rock   Fairy    700  50     160      110   \n",
              "797  720    HoopaHoopa Confined  Psychic   Ghost    600  80     110       60   \n",
              "798  720     HoopaHoopa Unbound  Psychic    Dark    680  80     160       60   \n",
              "799  721              Volcanion     Fire   Water    600  80     110      120   \n",
              "\n",
              "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
              "0         65       65     45           1      False  \n",
              "1         80       80     60           1      False  \n",
              "2        100      100     80           1      False  \n",
              "3        122      120     80           1      False  \n",
              "4         60       50     65           1      False  \n",
              "..       ...      ...    ...         ...        ...  \n",
              "795      100      150     50           6       True  \n",
              "796      160      110    110           6       True  \n",
              "797      150      130     70           6       True  \n",
              "798      170      130     80           6       True  \n",
              "799      130       90     70           6       True  \n",
              "\n",
              "[800 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-306dfa16-1d1a-46ba-be56-61faf5ceed7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>Name</th>\n",
              "      <th>Type 1</th>\n",
              "      <th>Type 2</th>\n",
              "      <th>Total</th>\n",
              "      <th>HP</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Defense</th>\n",
              "      <th>Sp. Atk</th>\n",
              "      <th>Sp. Def</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Generation</th>\n",
              "      <th>Legendary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Bulbasaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>318</td>\n",
              "      <td>45</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Ivysaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>405</td>\n",
              "      <td>60</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Venusaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>525</td>\n",
              "      <td>80</td>\n",
              "      <td>82</td>\n",
              "      <td>83</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>VenusaurMega Venusaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>625</td>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>123</td>\n",
              "      <td>122</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Charmander</td>\n",
              "      <td>Fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>309</td>\n",
              "      <td>39</td>\n",
              "      <td>52</td>\n",
              "      <td>43</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>719</td>\n",
              "      <td>Diancie</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Fairy</td>\n",
              "      <td>600</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>50</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>719</td>\n",
              "      <td>DiancieMega Diancie</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Fairy</td>\n",
              "      <td>700</td>\n",
              "      <td>50</td>\n",
              "      <td>160</td>\n",
              "      <td>110</td>\n",
              "      <td>160</td>\n",
              "      <td>110</td>\n",
              "      <td>110</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>720</td>\n",
              "      <td>HoopaHoopa Confined</td>\n",
              "      <td>Psychic</td>\n",
              "      <td>Ghost</td>\n",
              "      <td>600</td>\n",
              "      <td>80</td>\n",
              "      <td>110</td>\n",
              "      <td>60</td>\n",
              "      <td>150</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>720</td>\n",
              "      <td>HoopaHoopa Unbound</td>\n",
              "      <td>Psychic</td>\n",
              "      <td>Dark</td>\n",
              "      <td>680</td>\n",
              "      <td>80</td>\n",
              "      <td>160</td>\n",
              "      <td>60</td>\n",
              "      <td>170</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>721</td>\n",
              "      <td>Volcanion</td>\n",
              "      <td>Fire</td>\n",
              "      <td>Water</td>\n",
              "      <td>600</td>\n",
              "      <td>80</td>\n",
              "      <td>110</td>\n",
              "      <td>120</td>\n",
              "      <td>130</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-306dfa16-1d1a-46ba-be56-61faf5ceed7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-306dfa16-1d1a-46ba-be56-61faf5ceed7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-306dfa16-1d1a-46ba-be56-61faf5ceed7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Select features"
      ],
      "metadata": {
        "id": "3oP-GBavWTcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modified_df = original_df[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']]\n",
        "modified_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xuHgiUBdWHnB",
        "outputId": "b45d5c1a-385a-4dd1-963b-38174c1deca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   HP  Attack  Defense  Sp. Atk  Sp. Def  Speed\n",
              "0  45      49       49       65       65     45\n",
              "1  60      62       63       80       80     60\n",
              "2  80      82       83      100      100     80\n",
              "3  80     100      123      122      120     80\n",
              "4  39      52       43       60       50     65"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f95f44b-09f8-4f24-be5c-501df1e161dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HP</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Defense</th>\n",
              "      <th>Sp. Atk</th>\n",
              "      <th>Sp. Def</th>\n",
              "      <th>Speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>80</td>\n",
              "      <td>82</td>\n",
              "      <td>83</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>123</td>\n",
              "      <td>122</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39</td>\n",
              "      <td>52</td>\n",
              "      <td>43</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f95f44b-09f8-4f24-be5c-501df1e161dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f95f44b-09f8-4f24-be5c-501df1e161dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f95f44b-09f8-4f24-be5c-501df1e161dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Split into 3 partitions: Train, Val & Test"
      ],
      "metadata": {
        "id": "Q1zYLwn0W5vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_df = modified_df.sample(frac=1)\n",
        "shuffled_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Moecyzc3W5Aq",
        "outputId": "116225c2-14b6-4e64-8302-55cf1f89c5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      HP  Attack  Defense  Sp. Atk  Sp. Def  Speed\n",
              "559  110     123       65      100       65     65\n",
              "794  108     100      121       81       95     95\n",
              "10    59      63       80       65       80     58\n",
              "659   74      94      131       54      116     20\n",
              "413   80     145      150      105      110    110"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d56bbbae-df09-475a-a0d1-623176cd1447\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HP</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Defense</th>\n",
              "      <th>Sp. Atk</th>\n",
              "      <th>Sp. Def</th>\n",
              "      <th>Speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>110</td>\n",
              "      <td>123</td>\n",
              "      <td>65</td>\n",
              "      <td>100</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794</th>\n",
              "      <td>108</td>\n",
              "      <td>100</td>\n",
              "      <td>121</td>\n",
              "      <td>81</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>59</td>\n",
              "      <td>63</td>\n",
              "      <td>80</td>\n",
              "      <td>65</td>\n",
              "      <td>80</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659</th>\n",
              "      <td>74</td>\n",
              "      <td>94</td>\n",
              "      <td>131</td>\n",
              "      <td>54</td>\n",
              "      <td>116</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>80</td>\n",
              "      <td>145</td>\n",
              "      <td>150</td>\n",
              "      <td>105</td>\n",
              "      <td>110</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d56bbbae-df09-475a-a0d1-623176cd1447')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d56bbbae-df09-475a-a0d1-623176cd1447 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d56bbbae-df09-475a-a0d1-623176cd1447');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tables.group import TransactionG\n",
        "train_df = shuffled_df[:500]\n",
        "val_df = shuffled_df[500:650]\n",
        "test_df = shuffled_df[650:]\n",
        "\n",
        "len(train_df), len(val_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KumQBwgXzcC",
        "outputId": "f0d7d156-76aa-4bc8-9b14-35136e53d476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 150, 150)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = train_df.to_numpy()[:, :-1], train_df.to_numpy()[:, -1]\n",
        "X_val, y_val = val_df.to_numpy()[:, :-1], val_df.to_numpy()[:, -1]\n",
        "X_test, y_test = test_df.to_numpy()[:, :-1], test_df.to_numpy()[:, -1]\n",
        "\n",
        "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape), (X_test.shape, y_test.shape)\n",
        "\n",
        "# Ens dona quantes (files, columnes) te cada shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr1YoKUTYvGb",
        "outputId": "a6c627a5-31b0-4bfa-ccac-8c548465459f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((500, 5), (500,)), ((150, 5), (150,)), ((150, 5), (150,)))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Preprocess the inputs"
      ],
      "metadata": {
        "id": "AxslTr2AYgty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "\n",
        "X_train_scaled, X_val_scaled, X_test_scaled = scaler.transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n",
        "\n",
        "pd.DataFrame(X_train_scaled).hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "La6TMuXeYfKT",
        "outputId": "c1f94da1-094a-4861-d5d9-aea1c390bd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<AxesSubplot:title={'center':'0'}>,\n",
              "        <AxesSubplot:title={'center':'1'}>],\n",
              "       [<AxesSubplot:title={'center':'2'}>,\n",
              "        <AxesSubplot:title={'center':'3'}>],\n",
              "       [<AxesSubplot:title={'center':'4'}>, <AxesSubplot:>]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Pick the best model w/ lowest validation error"
      ],
      "metadata": {
        "id": "uM06FeoMb0mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "average_speed = y_train.mean()\n",
        "\n",
        "mean_absolute_error(y_val, [average_speed]*len(y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvjCAKj0bdbj",
        "outputId": "1ac4c3f0-daa6-4a11-b56c-3c7889c1c1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.66112"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linear_model = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "mean_absolute_error(y_val, linear_model.predict(X_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFVnIe_0cu5t",
        "outputId": "12be7ccf-64b3-4ab0-9590-dcafe783f486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.915843060903303"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "random_forest = RandomForestRegressor().fit(X_train, y_train)\n",
        "\n",
        "mean_absolute_error(y_val, random_forest.predict(X_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNCpPWO8dZ70",
        "outputId": "5bb915b7-aa75-4221-dec4-d62851b30785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.285974126984126"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fer el model amb neuronal networks o deep learning\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model_1 = Sequential([layers.Input((5,)),\n",
        "                      layers.Dense(1)])\n",
        "\n",
        "model_1.compile(loss='mse', optimizer=Adam(learning_rate=0.01), metrics=['mean_absolute_error'])\n",
        "\n",
        "model_1.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db79vHKMezVV",
        "outputId": "83520ae6-eb7b-4d56-a34a-021e48a21461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 24ms/step - loss: 5470.1240 - mean_absolute_error: 60.8827 - val_loss: 3181.6758 - val_mean_absolute_error: 42.1478\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1723.1058 - mean_absolute_error: 32.6623 - val_loss: 1903.9183 - val_mean_absolute_error: 32.8377\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1520.2562 - mean_absolute_error: 30.8467 - val_loss: 1848.0089 - val_mean_absolute_error: 32.5149\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1433.6261 - mean_absolute_error: 29.9828 - val_loss: 1781.2075 - val_mean_absolute_error: 31.7354\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1357.4224 - mean_absolute_error: 29.1481 - val_loss: 1707.2340 - val_mean_absolute_error: 31.1460\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1294.4604 - mean_absolute_error: 28.5451 - val_loss: 1625.5481 - val_mean_absolute_error: 30.4668\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1233.5609 - mean_absolute_error: 27.9216 - val_loss: 1540.0555 - val_mean_absolute_error: 29.7509\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1180.3411 - mean_absolute_error: 27.4188 - val_loss: 1470.3071 - val_mean_absolute_error: 29.1716\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1126.3480 - mean_absolute_error: 26.7758 - val_loss: 1402.8821 - val_mean_absolute_error: 28.6143\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1076.1547 - mean_absolute_error: 26.2093 - val_loss: 1331.1871 - val_mean_absolute_error: 28.0057\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1030.5546 - mean_absolute_error: 25.7004 - val_loss: 1272.8644 - val_mean_absolute_error: 27.5533\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 988.7170 - mean_absolute_error: 25.2472 - val_loss: 1216.1733 - val_mean_absolute_error: 27.0920\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 951.2366 - mean_absolute_error: 24.8412 - val_loss: 1157.0881 - val_mean_absolute_error: 26.5690\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 917.8057 - mean_absolute_error: 24.4228 - val_loss: 1112.7625 - val_mean_absolute_error: 26.1826\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 886.4711 - mean_absolute_error: 24.0490 - val_loss: 1067.6495 - val_mean_absolute_error: 25.7525\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 859.6185 - mean_absolute_error: 23.7361 - val_loss: 1023.8322 - val_mean_absolute_error: 25.3351\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 837.3735 - mean_absolute_error: 23.4484 - val_loss: 988.3097 - val_mean_absolute_error: 24.9709\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 821.6666 - mean_absolute_error: 23.2796 - val_loss: 963.5918 - val_mean_absolute_error: 24.7472\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 796.2628 - mean_absolute_error: 22.9315 - val_loss: 922.2042 - val_mean_absolute_error: 24.2748\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 781.6298 - mean_absolute_error: 22.7363 - val_loss: 904.5432 - val_mean_absolute_error: 24.0933\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 765.9387 - mean_absolute_error: 22.4746 - val_loss: 879.9580 - val_mean_absolute_error: 23.8071\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 752.1833 - mean_absolute_error: 22.2795 - val_loss: 852.9348 - val_mean_absolute_error: 23.4765\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 740.3049 - mean_absolute_error: 22.1157 - val_loss: 841.7033 - val_mean_absolute_error: 23.3785\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 729.5102 - mean_absolute_error: 21.9398 - val_loss: 819.1545 - val_mean_absolute_error: 23.0832\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 723.9723 - mean_absolute_error: 21.8035 - val_loss: 802.3347 - val_mean_absolute_error: 22.8723\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 714.1544 - mean_absolute_error: 21.6574 - val_loss: 789.0184 - val_mean_absolute_error: 22.7059\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 707.0603 - mean_absolute_error: 21.5551 - val_loss: 778.7562 - val_mean_absolute_error: 22.5781\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 701.5494 - mean_absolute_error: 21.4528 - val_loss: 767.1788 - val_mean_absolute_error: 22.4125\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 697.0690 - mean_absolute_error: 21.3908 - val_loss: 755.6760 - val_mean_absolute_error: 22.2214\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 693.2368 - mean_absolute_error: 21.3015 - val_loss: 750.9758 - val_mean_absolute_error: 22.1766\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 687.4044 - mean_absolute_error: 21.2178 - val_loss: 743.5974 - val_mean_absolute_error: 22.0581\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 683.8030 - mean_absolute_error: 21.1505 - val_loss: 730.3148 - val_mean_absolute_error: 21.7891\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 681.6085 - mean_absolute_error: 21.1133 - val_loss: 725.7781 - val_mean_absolute_error: 21.7260\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 676.9688 - mean_absolute_error: 21.0563 - val_loss: 724.4273 - val_mean_absolute_error: 21.7352\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 675.7365 - mean_absolute_error: 21.0187 - val_loss: 715.8063 - val_mean_absolute_error: 21.5599\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 672.5848 - mean_absolute_error: 20.9757 - val_loss: 714.2842 - val_mean_absolute_error: 21.5419\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 669.0872 - mean_absolute_error: 20.9197 - val_loss: 706.3127 - val_mean_absolute_error: 21.3620\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 667.5792 - mean_absolute_error: 20.8917 - val_loss: 702.0661 - val_mean_absolute_error: 21.3006\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 666.5630 - mean_absolute_error: 20.8802 - val_loss: 696.6983 - val_mean_absolute_error: 21.1860\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 664.7088 - mean_absolute_error: 20.8258 - val_loss: 697.4400 - val_mean_absolute_error: 21.2351\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 662.5150 - mean_absolute_error: 20.7930 - val_loss: 693.9980 - val_mean_absolute_error: 21.1681\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 666.6794 - mean_absolute_error: 20.8775 - val_loss: 686.8286 - val_mean_absolute_error: 20.9808\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 660.9546 - mean_absolute_error: 20.7492 - val_loss: 690.4130 - val_mean_absolute_error: 21.1053\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 658.9527 - mean_absolute_error: 20.7182 - val_loss: 684.2935 - val_mean_absolute_error: 20.9745\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 660.0806 - mean_absolute_error: 20.6985 - val_loss: 688.1555 - val_mean_absolute_error: 21.0558\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 658.9849 - mean_absolute_error: 20.7199 - val_loss: 681.0804 - val_mean_absolute_error: 20.9002\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 656.8815 - mean_absolute_error: 20.6371 - val_loss: 680.9100 - val_mean_absolute_error: 20.8993\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 659.0813 - mean_absolute_error: 20.7255 - val_loss: 678.6293 - val_mean_absolute_error: 20.8512\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 657.2339 - mean_absolute_error: 20.6611 - val_loss: 670.8222 - val_mean_absolute_error: 20.6422\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 657.8459 - mean_absolute_error: 20.6603 - val_loss: 687.3514 - val_mean_absolute_error: 21.0178\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 660.9835 - mean_absolute_error: 20.6679 - val_loss: 668.5378 - val_mean_absolute_error: 20.5585\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 658.8981 - mean_absolute_error: 20.6773 - val_loss: 680.8954 - val_mean_absolute_error: 20.8886\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 650.0220 - mean_absolute_error: 20.4800 - val_loss: 663.8013 - val_mean_absolute_error: 20.4094\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 658.9646 - mean_absolute_error: 20.6425 - val_loss: 679.1224 - val_mean_absolute_error: 20.8413\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 673.6440 - mean_absolute_error: 20.7783 - val_loss: 663.2371 - val_mean_absolute_error: 20.3810\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 652.9385 - mean_absolute_error: 20.5356 - val_loss: 673.9352 - val_mean_absolute_error: 20.7335\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 659.2963 - mean_absolute_error: 20.5749 - val_loss: 660.5733 - val_mean_absolute_error: 20.3180\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 652.9678 - mean_absolute_error: 20.6176 - val_loss: 677.3660 - val_mean_absolute_error: 20.7835\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 648.4503 - mean_absolute_error: 20.5045 - val_loss: 659.4630 - val_mean_absolute_error: 20.3343\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 650.6705 - mean_absolute_error: 20.4889 - val_loss: 676.5436 - val_mean_absolute_error: 20.7616\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 653.6393 - mean_absolute_error: 20.5072 - val_loss: 662.4810 - val_mean_absolute_error: 20.4337\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 648.0923 - mean_absolute_error: 20.4370 - val_loss: 663.3282 - val_mean_absolute_error: 20.4655\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 646.7552 - mean_absolute_error: 20.4149 - val_loss: 667.6274 - val_mean_absolute_error: 20.5695\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 648.2406 - mean_absolute_error: 20.4324 - val_loss: 657.5975 - val_mean_absolute_error: 20.2628\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 646.4688 - mean_absolute_error: 20.4072 - val_loss: 659.9278 - val_mean_absolute_error: 20.3580\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 645.3395 - mean_absolute_error: 20.4277 - val_loss: 667.3385 - val_mean_absolute_error: 20.5538\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 651.0375 - mean_absolute_error: 20.4642 - val_loss: 669.9037 - val_mean_absolute_error: 20.6006\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 644.8130 - mean_absolute_error: 20.3926 - val_loss: 657.1763 - val_mean_absolute_error: 20.2852\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 647.5221 - mean_absolute_error: 20.4212 - val_loss: 654.0494 - val_mean_absolute_error: 20.1468\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 646.4620 - mean_absolute_error: 20.4271 - val_loss: 659.8606 - val_mean_absolute_error: 20.3701\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 647.4009 - mean_absolute_error: 20.4002 - val_loss: 658.1223 - val_mean_absolute_error: 20.3120\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 646.0843 - mean_absolute_error: 20.4264 - val_loss: 662.6050 - val_mean_absolute_error: 20.4330\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 647.2581 - mean_absolute_error: 20.4336 - val_loss: 673.3870 - val_mean_absolute_error: 20.6392\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 647.0749 - mean_absolute_error: 20.4128 - val_loss: 652.1702 - val_mean_absolute_error: 20.1187\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 646.2988 - mean_absolute_error: 20.4017 - val_loss: 671.1411 - val_mean_absolute_error: 20.5944\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 641.6403 - mean_absolute_error: 20.2760 - val_loss: 650.4529 - val_mean_absolute_error: 20.0517\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 647.3652 - mean_absolute_error: 20.4140 - val_loss: 655.8557 - val_mean_absolute_error: 20.2643\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 644.9696 - mean_absolute_error: 20.3710 - val_loss: 653.1383 - val_mean_absolute_error: 20.1785\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 643.9337 - mean_absolute_error: 20.3384 - val_loss: 649.0383 - val_mean_absolute_error: 20.0266\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 648.6295 - mean_absolute_error: 20.3508 - val_loss: 657.1790 - val_mean_absolute_error: 20.2998\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 647.7769 - mean_absolute_error: 20.4145 - val_loss: 665.1549 - val_mean_absolute_error: 20.4721\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 647.2602 - mean_absolute_error: 20.3888 - val_loss: 651.6857 - val_mean_absolute_error: 20.1454\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 645.2381 - mean_absolute_error: 20.3421 - val_loss: 648.7117 - val_mean_absolute_error: 20.0144\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 651.4800 - mean_absolute_error: 20.5150 - val_loss: 697.7991 - val_mean_absolute_error: 20.9440\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 654.7183 - mean_absolute_error: 20.4496 - val_loss: 647.3453 - val_mean_absolute_error: 19.9028\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 648.6586 - mean_absolute_error: 20.4133 - val_loss: 650.3203 - val_mean_absolute_error: 20.1291\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 644.5273 - mean_absolute_error: 20.3250 - val_loss: 662.9091 - val_mean_absolute_error: 20.4150\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.1310 - mean_absolute_error: 20.2759 - val_loss: 646.3965 - val_mean_absolute_error: 19.9935\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.1033 - mean_absolute_error: 20.3143 - val_loss: 661.3992 - val_mean_absolute_error: 20.3983\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.9527 - mean_absolute_error: 20.2846 - val_loss: 646.6093 - val_mean_absolute_error: 19.9929\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 641.1064 - mean_absolute_error: 20.2504 - val_loss: 662.8672 - val_mean_absolute_error: 20.4169\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.9358 - mean_absolute_error: 20.2992 - val_loss: 655.2498 - val_mean_absolute_error: 20.2677\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 646.3746 - mean_absolute_error: 20.3590 - val_loss: 650.2939 - val_mean_absolute_error: 20.1414\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 644.1766 - mean_absolute_error: 20.3039 - val_loss: 645.0270 - val_mean_absolute_error: 19.9607\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 639.6605 - mean_absolute_error: 20.2271 - val_loss: 648.6716 - val_mean_absolute_error: 20.1128\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 640.4288 - mean_absolute_error: 20.2419 - val_loss: 644.6207 - val_mean_absolute_error: 19.9649\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 639.5753 - mean_absolute_error: 20.2355 - val_loss: 654.4603 - val_mean_absolute_error: 20.2561\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.8290 - mean_absolute_error: 20.2458 - val_loss: 657.0144 - val_mean_absolute_error: 20.3120\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 646.8630 - mean_absolute_error: 20.3099 - val_loss: 642.9724 - val_mean_absolute_error: 19.7581\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 639.0461 - mean_absolute_error: 20.2938 - val_loss: 679.6473 - val_mean_absolute_error: 20.6748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e104a6850>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrmWolUzhodH",
        "outputId": "91b22915-5b3a-4dfd-f83c-3cc461948074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model_2 = Sequential([layers.Input((5,)),\n",
        "                      layers.Dense(32),\n",
        "                      layers.Dense(32),\n",
        "                      layers.Dense(1)])\n",
        "\n",
        "model_2.compile(loss='mse', optimizer=Adam(learning_rate=0.01), metrics=['mean_absolute_error'])\n",
        "\n",
        "model_2.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7J7qQuxhb2u",
        "outputId": "06110553-66ae-4c98-c32f-addb4f8223b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 2888.6611 - mean_absolute_error: 41.4817 - val_loss: 852.5414 - val_mean_absolute_error: 23.2755\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 806.6719 - mean_absolute_error: 22.6661 - val_loss: 669.3750 - val_mean_absolute_error: 20.3254\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 662.5271 - mean_absolute_error: 20.5399 - val_loss: 664.3661 - val_mean_absolute_error: 19.8779\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 664.8396 - mean_absolute_error: 20.6356 - val_loss: 687.6309 - val_mean_absolute_error: 20.7687\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 668.2023 - mean_absolute_error: 20.7631 - val_loss: 694.5010 - val_mean_absolute_error: 20.7877\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 671.5929 - mean_absolute_error: 20.6764 - val_loss: 663.2570 - val_mean_absolute_error: 20.2963\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 669.1442 - mean_absolute_error: 20.7341 - val_loss: 660.9796 - val_mean_absolute_error: 19.9148\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 700.8423 - mean_absolute_error: 21.2963 - val_loss: 672.1077 - val_mean_absolute_error: 20.5479\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 675.2542 - mean_absolute_error: 20.8694 - val_loss: 681.6688 - val_mean_absolute_error: 20.7425\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 662.0700 - mean_absolute_error: 20.6479 - val_loss: 694.4043 - val_mean_absolute_error: 20.6234\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 671.6234 - mean_absolute_error: 20.6288 - val_loss: 669.9999 - val_mean_absolute_error: 20.5157\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 668.5248 - mean_absolute_error: 20.6107 - val_loss: 859.4647 - val_mean_absolute_error: 23.2527\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 749.4402 - mean_absolute_error: 22.1336 - val_loss: 744.1591 - val_mean_absolute_error: 21.7118\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 663.7629 - mean_absolute_error: 20.6626 - val_loss: 644.0913 - val_mean_absolute_error: 19.8087\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 654.3865 - mean_absolute_error: 20.4444 - val_loss: 678.3708 - val_mean_absolute_error: 20.6347\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 681.0286 - mean_absolute_error: 20.8944 - val_loss: 749.5457 - val_mean_absolute_error: 21.6975\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 699.4848 - mean_absolute_error: 20.9941 - val_loss: 665.9575 - val_mean_absolute_error: 20.4544\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 695.6838 - mean_absolute_error: 21.0260 - val_loss: 660.9478 - val_mean_absolute_error: 19.9674\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 670.1743 - mean_absolute_error: 20.8676 - val_loss: 638.6087 - val_mean_absolute_error: 19.6619\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 649.3730 - mean_absolute_error: 20.4382 - val_loss: 648.0421 - val_mean_absolute_error: 19.9256\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 655.1673 - mean_absolute_error: 20.6198 - val_loss: 679.2903 - val_mean_absolute_error: 20.8259\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 654.7966 - mean_absolute_error: 20.4545 - val_loss: 639.0327 - val_mean_absolute_error: 19.7295\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 663.6745 - mean_absolute_error: 20.4553 - val_loss: 656.5028 - val_mean_absolute_error: 20.1173\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 651.7838 - mean_absolute_error: 20.5284 - val_loss: 643.7550 - val_mean_absolute_error: 19.8538\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 647.8270 - mean_absolute_error: 20.3337 - val_loss: 652.8735 - val_mean_absolute_error: 20.1935\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 654.8348 - mean_absolute_error: 20.5694 - val_loss: 634.1382 - val_mean_absolute_error: 19.6865\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 691.6768 - mean_absolute_error: 21.0513 - val_loss: 644.6174 - val_mean_absolute_error: 19.7046\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 654.5703 - mean_absolute_error: 20.4935 - val_loss: 641.4586 - val_mean_absolute_error: 19.7515\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 668.6361 - mean_absolute_error: 20.8521 - val_loss: 632.9955 - val_mean_absolute_error: 19.7929\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 667.2928 - mean_absolute_error: 20.5797 - val_loss: 645.0485 - val_mean_absolute_error: 20.0358\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 657.3210 - mean_absolute_error: 20.5002 - val_loss: 637.2869 - val_mean_absolute_error: 19.9664\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 676.7001 - mean_absolute_error: 20.9073 - val_loss: 652.6704 - val_mean_absolute_error: 19.4370\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 646.1146 - mean_absolute_error: 20.3541 - val_loss: 616.6984 - val_mean_absolute_error: 19.3897\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 639.5726 - mean_absolute_error: 20.1267 - val_loss: 689.5074 - val_mean_absolute_error: 20.7439\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 649.1553 - mean_absolute_error: 20.3536 - val_loss: 613.9226 - val_mean_absolute_error: 19.3158\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 659.5034 - mean_absolute_error: 20.4999 - val_loss: 643.1199 - val_mean_absolute_error: 19.5271\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 658.5614 - mean_absolute_error: 20.6330 - val_loss: 637.9203 - val_mean_absolute_error: 19.3857\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 651.3135 - mean_absolute_error: 20.3573 - val_loss: 609.2070 - val_mean_absolute_error: 19.2170\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 659.1490 - mean_absolute_error: 20.4933 - val_loss: 712.7430 - val_mean_absolute_error: 21.2173\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 647.0690 - mean_absolute_error: 20.2951 - val_loss: 668.0661 - val_mean_absolute_error: 20.4107\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 654.7332 - mean_absolute_error: 20.4670 - val_loss: 649.6191 - val_mean_absolute_error: 20.1579\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 632.7504 - mean_absolute_error: 20.1787 - val_loss: 621.7896 - val_mean_absolute_error: 19.6468\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 634.6726 - mean_absolute_error: 20.1200 - val_loss: 613.5502 - val_mean_absolute_error: 19.3311\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 646.8192 - mean_absolute_error: 20.3388 - val_loss: 635.6399 - val_mean_absolute_error: 19.5230\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 652.9190 - mean_absolute_error: 20.4660 - val_loss: 610.0457 - val_mean_absolute_error: 19.3834\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 672.2892 - mean_absolute_error: 20.7992 - val_loss: 695.9309 - val_mean_absolute_error: 21.0310\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 664.3353 - mean_absolute_error: 20.7003 - val_loss: 643.6710 - val_mean_absolute_error: 19.9427\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.5146 - mean_absolute_error: 20.5763 - val_loss: 622.8572 - val_mean_absolute_error: 19.7311\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 634.2601 - mean_absolute_error: 20.2516 - val_loss: 618.6995 - val_mean_absolute_error: 18.9903\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 646.0568 - mean_absolute_error: 20.4430 - val_loss: 616.3267 - val_mean_absolute_error: 19.4991\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 655.4973 - mean_absolute_error: 20.3543 - val_loss: 618.0080 - val_mean_absolute_error: 19.6125\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 644.0248 - mean_absolute_error: 20.4020 - val_loss: 604.5624 - val_mean_absolute_error: 19.0532\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 621.7144 - mean_absolute_error: 20.0003 - val_loss: 606.1702 - val_mean_absolute_error: 19.1661\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 646.7173 - mean_absolute_error: 20.2964 - val_loss: 640.4974 - val_mean_absolute_error: 19.6754\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 651.5092 - mean_absolute_error: 20.4555 - val_loss: 602.5969 - val_mean_absolute_error: 19.1343\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 633.1655 - mean_absolute_error: 19.9813 - val_loss: 614.7971 - val_mean_absolute_error: 19.5430\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 619.2565 - mean_absolute_error: 19.9074 - val_loss: 605.7310 - val_mean_absolute_error: 18.8321\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 634.9233 - mean_absolute_error: 20.0459 - val_loss: 595.2354 - val_mean_absolute_error: 18.9777\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 652.3096 - mean_absolute_error: 20.3285 - val_loss: 629.8830 - val_mean_absolute_error: 19.9855\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 677.4368 - mean_absolute_error: 20.9535 - val_loss: 640.9501 - val_mean_absolute_error: 19.3957\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 661.5576 - mean_absolute_error: 20.3990 - val_loss: 590.1411 - val_mean_absolute_error: 18.8091\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 621.0187 - mean_absolute_error: 19.9279 - val_loss: 628.3699 - val_mean_absolute_error: 19.8388\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 643.1152 - mean_absolute_error: 20.4538 - val_loss: 616.7900 - val_mean_absolute_error: 19.5378\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 641.9009 - mean_absolute_error: 20.2223 - val_loss: 604.2727 - val_mean_absolute_error: 19.4503\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 645.7346 - mean_absolute_error: 20.5490 - val_loss: 585.9428 - val_mean_absolute_error: 18.7534\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 635.1530 - mean_absolute_error: 20.3011 - val_loss: 591.5827 - val_mean_absolute_error: 18.9547\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 634.6376 - mean_absolute_error: 20.4353 - val_loss: 656.1359 - val_mean_absolute_error: 20.3511\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 626.7440 - mean_absolute_error: 20.0899 - val_loss: 615.7441 - val_mean_absolute_error: 19.5202\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 616.3428 - mean_absolute_error: 20.0041 - val_loss: 642.1209 - val_mean_absolute_error: 20.1693\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 640.6169 - mean_absolute_error: 20.1259 - val_loss: 681.2000 - val_mean_absolute_error: 20.7517\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 653.1880 - mean_absolute_error: 20.6984 - val_loss: 616.1158 - val_mean_absolute_error: 18.7536\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 685.9803 - mean_absolute_error: 21.2372 - val_loss: 618.2481 - val_mean_absolute_error: 19.2844\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 624.6583 - mean_absolute_error: 20.0270 - val_loss: 608.3093 - val_mean_absolute_error: 19.5137\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 631.0338 - mean_absolute_error: 20.2021 - val_loss: 625.3805 - val_mean_absolute_error: 18.8591\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 622.0156 - mean_absolute_error: 20.0375 - val_loss: 603.8896 - val_mean_absolute_error: 19.5180\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 607.2446 - mean_absolute_error: 19.7907 - val_loss: 575.8323 - val_mean_absolute_error: 18.6647\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 612.1766 - mean_absolute_error: 19.8571 - val_loss: 591.2211 - val_mean_absolute_error: 19.1133\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 620.4396 - mean_absolute_error: 19.8585 - val_loss: 628.5715 - val_mean_absolute_error: 19.8195\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 622.1484 - mean_absolute_error: 20.2897 - val_loss: 774.1536 - val_mean_absolute_error: 22.1570\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 657.3662 - mean_absolute_error: 20.5118 - val_loss: 576.6774 - val_mean_absolute_error: 18.6395\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 611.2112 - mean_absolute_error: 19.9118 - val_loss: 585.8729 - val_mean_absolute_error: 18.9821\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 614.2609 - mean_absolute_error: 20.0140 - val_loss: 612.9554 - val_mean_absolute_error: 19.4714\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 634.1685 - mean_absolute_error: 20.1346 - val_loss: 582.2960 - val_mean_absolute_error: 18.7913\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 625.0526 - mean_absolute_error: 19.9359 - val_loss: 711.9771 - val_mean_absolute_error: 21.2981\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 634.7932 - mean_absolute_error: 20.2417 - val_loss: 573.0245 - val_mean_absolute_error: 18.8482\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 594.8835 - mean_absolute_error: 19.6410 - val_loss: 576.8754 - val_mean_absolute_error: 18.4098\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 628.1295 - mean_absolute_error: 20.0271 - val_loss: 587.2385 - val_mean_absolute_error: 18.5743\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 617.0872 - mean_absolute_error: 19.9287 - val_loss: 565.9385 - val_mean_absolute_error: 18.4955\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 631.5082 - mean_absolute_error: 20.2398 - val_loss: 589.7870 - val_mean_absolute_error: 18.8965\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 640.7427 - mean_absolute_error: 20.3180 - val_loss: 581.7789 - val_mean_absolute_error: 18.5103\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 634.5345 - mean_absolute_error: 20.2622 - val_loss: 693.2510 - val_mean_absolute_error: 21.0025\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 659.5451 - mean_absolute_error: 20.5808 - val_loss: 688.3168 - val_mean_absolute_error: 20.9044\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 623.2921 - mean_absolute_error: 19.9536 - val_loss: 562.3815 - val_mean_absolute_error: 18.2895\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 651.8525 - mean_absolute_error: 20.4720 - val_loss: 588.8315 - val_mean_absolute_error: 19.1234\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 622.7034 - mean_absolute_error: 20.1337 - val_loss: 581.3499 - val_mean_absolute_error: 18.9497\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 614.2921 - mean_absolute_error: 19.7659 - val_loss: 582.2992 - val_mean_absolute_error: 18.3898\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 617.3602 - mean_absolute_error: 19.9478 - val_loss: 571.3272 - val_mean_absolute_error: 18.8518\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 597.9612 - mean_absolute_error: 19.6448 - val_loss: 575.7426 - val_mean_absolute_error: 18.8093\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 599.4951 - mean_absolute_error: 19.5497 - val_loss: 562.3455 - val_mean_absolute_error: 18.4072\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 607.6823 - mean_absolute_error: 19.7366 - val_loss: 574.5245 - val_mean_absolute_error: 18.8815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e101ecb20>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujieau1Rh3Cm",
        "outputId": "9c412ae5-92ec-4f41-f2cc-0c3d52c57ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 32)                192       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,281\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Evaluate the chosen model"
      ],
      "metadata": {
        "id": "nlKul4uKdY4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escollim regressió lineal ja que és la millor \n",
        "# (si fos molt poc pitjor que les altres tambe l'escolliriem ja que es mes facil d'interpretar)\n",
        "\n",
        "mean_absolute_error(y_test, linear_model.predict(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqQUkDzteBS0",
        "outputId": "442fe726-aac2-4676-c2a5-1334c1da00f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.08714434236981"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "input_data = (80,82,83,100,100)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# changing the input_data to numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the array as we are predicting for one instance\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "print(input_data_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cX-Ots9jhNH",
        "outputId": "b0d2096f-c9ff-4e18-b686-efd8eff2794b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 80  82  83 100 100]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = linear_model.predict(input_data_reshaped)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvMk3kJmnnHR",
        "outputId": "35aeb90d-e58e-44c2-e20c-aff1b7d62b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[79.39148736]\n"
          ]
        }
      ]
    }
  ]
}